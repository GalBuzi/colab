{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU9RUCCmL72dJ+pzeyJcyE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GalBuzi/colab/blob/main/vgg16_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq0G4Cg6BK6X"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from os import listdir, makedirs\n",
        "from os.path import join, exists, expanduser\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications import xception\n",
        "from keras.applications import inception_v3\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Lambda, Flatten\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from google.colab import files\n",
        "import io\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,log_loss\n",
        "\n",
        "drive.mount('gdrive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTHy36GmJFEP"
      },
      "source": [
        "**Question 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLwWP0DNTdHe"
      },
      "source": [
        "Data Exploration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAKdANLSJFVO"
      },
      "source": [
        "\n",
        "train_dir = 'gdrive/My Drive/dog-breed-identification/train/'\n",
        "csv_file = open('gdrive/My Drive/dog-breed-identification/labels.csv')\n",
        "label = pd.read_csv(csv_file)\n",
        "\n",
        "\n",
        "label_df = pd.DataFrame(label['breed'].value_counts()).reset_index() # count how many labels of each breed\n",
        "\n",
        "labels_list = list(label_df['index']) # all possible labels\n",
        "\n",
        "label_df.columns = ['breed_name', 'count'] # change cols names\n",
        "\n",
        "label_df.sort_values(by=\"count\", ascending=False)\n",
        "\n",
        "label = label[label['breed'].isin(label_df['breed_name'])]\n",
        "\n",
        "# # adding jpg ext.\n",
        "\n",
        "label['id_ext']=label['id'].apply(lambda x:x+'.jpg')\n",
        "label=label.reset_index()\n",
        "label=label.drop(['index','id'],axis=1)\n",
        "images_names = list(label['id_ext'].head(100))\n",
        "print(label)\n",
        "\n",
        "# find out details about the images samples\n",
        "images_dim = {}\n",
        "for img in images_names:\n",
        "  full_path = train_dir + img\n",
        "  n = cv2.imread(full_path)\n",
        "  shape_string = str(n.shape)\n",
        "  if not shape_string in images_dim:\n",
        "    images_dim[shape_string] = 1\n",
        "  else:\n",
        "    images_dim[shape_string] = images_dim[shape_string]+1\n",
        "\n",
        "plt.figure(figsize=(50,20))\n",
        "plt.bar(list(images_dim.keys()),list(images_dim.values()))\n",
        "plt.xlabel(\"Images_shape\", size=30)\n",
        "plt.ylabel(\"Frequency\", size=30)\n",
        "plt.xticks(rotation=90,fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKVN4zIyJGG8"
      },
      "source": [
        "a. \n",
        "\n",
        "*   the size of the data is: 10222 samples.\n",
        "\n",
        "b. \n",
        "\n",
        "  *     the data is images of difference kinds of dogs.\n",
        "\n",
        "  *     all images have 3 channels\n",
        "\n",
        "  *   as we can see from the plot, all images are not of the same dimensions\n",
        "\n",
        "  *   by first 100 images the popular dimension is (375,500)\n",
        "    \n",
        "  *   that means we need to pre-process our data and convert all images to same dimensions\n",
        "\n",
        "  *   we should use augmentation to enlarge our data and decrease the overfitting\n",
        "\n",
        "  *   because we are dealing with dogs picture, we can make augmentation like: minimal rotation, zoom in/out, horizontal flip, width/height shift range\n",
        "\n",
        "  *   we cant use vertical flip for example because it doen't suits to the problem we are trying to solve\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYZxp47QYPyv"
      },
      "source": [
        "plt.figure(figsize=(50,20))\n",
        "plt.bar(list(label_df['breed_name']),list(label_df['count']))\n",
        "plt.xlabel(\"breed_name\", size=30)\n",
        "plt.ylabel(\"Frequency\", size=30)\n",
        "plt.xticks(rotation=90,fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCUtaUcBYucH"
      },
      "source": [
        "c.\n",
        "\n",
        "  *   as we can see, the data isn't balanced, the most frequent breed appears more than 120 times and the least frequent breed appears between 60-70 times\n",
        "\n",
        "d. benchmarks ???\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBqsjfbAZ81Z"
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "fig = plt.figure(figsize=(32, 32))\n",
        "examples = label['id_ext'].head(36)\n",
        "count_pic = 0\n",
        "index = 0\n",
        "for e in examples:\n",
        "  sub = fig.add_subplot(8,8, count_pic+1 )\n",
        "  full_path = train_dir + e\n",
        "  emage = mpimg.imread(full_path)\n",
        "  sub.imshow(emage)\n",
        "  sub.set_title(label.loc[index,'breed'])\n",
        "  # sub.text(0,0, color='red', weight='bold',fontsize=15)\n",
        "  count_pic = count_pic + 1\n",
        "  index = index + 1\n",
        "  if count_pic==32:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90rDEBEySmv5"
      },
      "source": [
        "e. as we can see by the samples above:\n",
        "\n",
        "  *   there are breeds which is very easy to differ like 'boxer' and 'doberman' in row 3\n",
        "  *   there are also breeds which is very difficult to label like 'golden retriever' and 'labrador retriever' in the last row\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXNDw7cdUqRY"
      },
      "source": [
        "def save_model(model):\n",
        "    model_json = model.to_json()\n",
        "    with open(\"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    model.save_weights(\"model.h5\")\n",
        "\n",
        "def load_model():\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    return loaded_model\n",
        "\n",
        "def confusion_matrix_predict(model, validation_generator):\n",
        "    preds = model.predict(validation_generator)\n",
        "    predicts = np.argmax(preds, axis=1)  # return the predicted category in each sample in test set\n",
        "    print(confusion_matrix(validation_generator.index_array, predicts))\n",
        "    print('model accuracy on test set is: {}%'.format(accuracy_score(validation_generator.index_array, predicts) * 100))\n",
        "    sns.heatmap(confusion_matrix(validation_generator.index_array, predicts), cmap='Greens', annot=False, fmt='d')\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('True label')\n",
        "    plt.title('Classification results on test set')\n",
        "    plt.show()\n",
        "\n",
        "def plot_history(history):\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "# one hot\n",
        "\n",
        "label_onehot = pd.get_dummies(label,columns=['breed'],prefix=None)\n",
        "label_onehot.columns = label_onehot.columns.str.replace(r'breed_', '') # remove breed_ prefix\n",
        "label_onehot=label_onehot.rename(columns={'id_ext':'id'})\n",
        "label_onehot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu2JUzRyc4Qg"
      },
      "source": [
        "# Train and Test split\n",
        "\n",
        "train_df, validate_df = train_test_split(label_onehot, test_size=0.1)\n",
        "train_df = train_df.reset_index()\n",
        "validate_df = validate_df.reset_index()\n",
        "\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]\n",
        "\n",
        "print(train_df.shape, validate_df.shape)\n",
        "\n",
        "image_size = 224\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "y_columns = list(label['breed'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ltRBqlab3px"
      },
      "source": [
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1 #, preprocessing_function = preprocess_input\n",
        ")\n",
        "\n",
        "\n",
        "    \n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    r'gdrive/My Drive/dog-breed-identification/train',\n",
        "    x_col='id',\n",
        "    y_col=y_columns,\n",
        "    class_mode='raw',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator()\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df,\n",
        "    r'gdrive/My Drive/dog-breed-identification/train',\n",
        "    x_col='id',\n",
        "    y_col=y_columns,\n",
        "    class_mode='raw',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dCYHJVKbxbS"
      },
      "source": [
        "pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in pre_trained_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in pre_trained_model.layers[15:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('block5_pool') # last layer before last block\n",
        "last_output = last_layer.output\n",
        "\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(len(y_columns), activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU-xJ2_neaMi"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs = epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = total_validate//batch_size,\n",
        "    steps_per_epoch = total_train//batch_size\n",
        "    )\n",
        "# history = model.fit(train_generator, \n",
        "#                     batch_size=batch_size,\n",
        "#                     epochs=epochs,\n",
        "#                     validation_data=validation_generator,\n",
        "#                     validation_steps=total_validate//batch_size,\n",
        "#                     steps_per_epoch= total_train//batch_size\n",
        "#                     )\n",
        "\n",
        "loss, accuracy = model.evaluate_generator(validation_generator, total_validate//batch_size, workers=12)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))\n",
        "\n",
        "plot_history(history) \n",
        "confusion_matrix_predict(model,validation_generator)\n",
        "save_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}