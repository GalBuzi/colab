{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPndl8DKB7j8ZE1oI+DoLMk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GalBuzi/colab/blob/main/vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAFrSU-KRoxP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from os import listdir, makedirs\n",
        "from os.path import join, exists, expanduser\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications import xception\n",
        "from keras.applications import inception_v3\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Lambda, Flatten\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from google.colab import files\n",
        "import io\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')\n",
        "\n",
        "csv_file = open('gdrive/My Drive/dog-breed-identification/labels.csv')\n",
        "label = pd.read_csv(csv_file)\n",
        "\n",
        "label_df = pd.DataFrame(label['breed'].value_counts()).reset_index()\n",
        "label_df.columns = ['breed_name', 'count']\n",
        "label_df.sort_values(by=\"count\", ascending=False)\n",
        "label = label[label['breed'].isin(label_df['breed_name'])]\n",
        "\n",
        "# adding jpg ext.\n",
        "\n",
        "label['id_ext']=label['id'].apply(lambda x:x+'.jpg')\n",
        "label=label.reset_index()\n",
        "label=label.drop(['index','id'],axis=1)\n",
        "\n",
        "# one hot\n",
        "\n",
        "label_onehot = pd.get_dummies(label,columns=['breed'],prefix=None)\n",
        "print(label_onehot.columns)\n",
        "label_onehot.columns = label_onehot.columns.str.replace(r'breed_', '') # remove breed_ prefix\n",
        "label_onehot=label_onehot.rename(columns={'id_ext':'id'})\n",
        "sample=random.choice(label_onehot['id'])\n",
        "image=load_img('gdrive/My Drive/dog-breed-identification/train/' + sample)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh_AH3O4OkFv"
      },
      "source": [
        "def save_model(model):\n",
        "    model_json = model.to_json()\n",
        "    with open(\"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    model.save_weights(\"model.h5\")\n",
        "\n",
        "def load_model():\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    return loaded_model\n",
        "\n",
        "def confusion_matrix_predict(model,x_test):\n",
        "    preds = model.predict(x_test)\n",
        "    predicts = np.argmax(preds, axis=1) #return the predicted category in each sample in test set\n",
        "    print(confusion_matrix(y_test,predicts))\n",
        "    print('model accuracy on test set is: {}%'.format(accuracy_score(y_test,predicts)*100))\n",
        "    sns.heatmap(confusion_matrix(y_test,predicts),cmap='Greens',annot=False, fmt='d')\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('True label')\n",
        "    plt.title('Classification results on test set')\n",
        "    print()\n",
        "\n",
        "def plot_history(history):\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZPQheY_r8Li"
      },
      "source": [
        "\n",
        "# Train and Test split\n",
        "\n",
        "train_df, validate_df = train_test_split(label_onehot, test_size=0.1)\n",
        "train_df = train_df.reset_index()\n",
        "validate_df = validate_df.reset_index()\n",
        "\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]\n",
        "\n",
        "print(train_df.shape, validate_df.shape)\n",
        "\n",
        "image_size = 224\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5wwVHc3sDdP"
      },
      "source": [
        "\n",
        "pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in pre_trained_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in pre_trained_model.layers[15:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "\n",
        "y_columns = list(label['breed'].unique())\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(len(y_columns), activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu9r0ym0sPCp"
      },
      "source": [
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "\n",
        "    \n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    r'gdrive/My Drive/dog-breed-identification/train',\n",
        "    x_col='id',\n",
        "    y_col=y_columns,\n",
        "    class_mode='raw',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df,\n",
        "    r'gdrive/My Drive/dog-breed-identification/train',\n",
        "    x_col='id',\n",
        "    y_col=y_columns,\n",
        "    class_mode='raw',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGui-ujsadg"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size)\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate_generator(validation_generator, total_validate//batch_size, workers=12)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))\n",
        "\n",
        "\n",
        "plot_history(history) \n",
        "confusion_matrix_predict(model,validate_df)\n",
        "save_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}